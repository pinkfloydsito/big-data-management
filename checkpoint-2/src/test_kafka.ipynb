{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d2d787-c7cc-4086-9948-f0c3beb0f18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java classpath:\n",
      "/usr/local/spark/conf/:/usr/local/spark/jars/netty-transport-native-epoll-4.1.96.Final-linux-aarch_64.jar:/usr/local/spark/jars/kubernetes-model-resource-6.7.2.jar:/usr/local/spark/jars/spark-sketch_2.12-3.5.3.jar:/usr/local/spark/jars/commons-compress-1.23.0.jar:/usr/local/spark/jars/kubernetes-model-storageclass-6.7.2.jar:/usr/local/spark/jars/metrics-jmx-4.2.19.jar:/usr/local/spark/jars/spark-catalyst_2.12-3.5.3.jar:/usr/local/spark/jars/jersey-server-2.40.jar:/usr/local/spark/jars/spire_2.12-0.17.0.jar:/usr/local/spark/jars/hive-serde-2.3.9.jar:/usr/local/spark/jars/snakeyaml-2.0.jar:/usr/local/spark/jars/aopalliance-repackaged-2.6.1.jar:/usr/local/spark/jars/avro-1.11.2.jar:/usr/local/spark/jars/json4s-core_2.12-3.7.0-M11.jar:/usr/local/spark/jars/netty-transport-native-unix-common-4.1.96.Final.jar:/usr/local/spark/jars/audience-annotations-0.5.0.jar:/usr/local/spark/jars/commons-pool-1.5.4.jar:/usr/local/spark/jars/datanucleus-core-4.1.17.jar:/usr/local/spark/jars/jsr305-3.0.0.jar:/usr/local/spark/jars/univocity-parsers-2.9.1.jar:/usr/local/spark/jars/spark-kubernetes_2.12-3.5.3.jar:/usr/local/spark/jars/antlr4-runtime-4.9.3.jar:/usr/local/spark/jars/osgi-resource-locator-1.0.3.jar:/usr/local/spark/jars/curator-framework-2.13.0.jar:/usr/local/spark/jars/oro-2.0.8.jar:/usr/local/spark/jars/httpcore-4.4.16.jar:/usr/local/spark/jars/curator-recipes-2.13.0.jar:/usr/local/spark/jars/snappy-java-1.1.10.5.jar:/usr/local/spark/jars/commons-codec-1.16.1.jar:/usr/local/spark/jars/jaxb-runtime-2.3.2.jar:/usr/local/spark/jars/jackson-annotations-2.15.2.jar:/usr/local/spark/jars/paranamer-2.8.jar:/usr/local/spark/jars/hadoop-yarn-server-web-proxy-3.3.4.jar:/usr/local/spark/jars/ST4-4.0.4.jar:/usr/local/spark/jars/netty-codec-4.1.96.Final.jar:/usr/local/spark/jars/orc-core-1.9.4-shaded-protobuf.jar:/usr/local/spark/jars/RoaringBitmap-0.9.45.jar:/usr/local/spark/jars/datanucleus-api-jdo-4.2.4.jar:/usr/local/spark/jars/chill-java-0.10.0.jar:/usr/local/spark/jars/xbean-asm9-shaded-4.23.jar:/usr/local/spark/jars/stream-2.9.6.jar:/usr/local/spark/jars/kubernetes-model-coordination-6.7.2.jar:/usr/local/spark/jars/commons-lang3-3.12.0.jar:/usr/local/spark/jars/scala-library-2.12.18.jar:/usr/local/spark/jars/jdo-api-3.0.1.jar:/usr/local/spark/jars/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/usr/local/spark/jars/netty-transport-4.1.96.Final.jar:/usr/local/spark/jars/logging-interceptor-3.12.12.jar:/usr/local/spark/jars/kubernetes-model-autoscaling-6.7.2.jar:/usr/local/spark/jars/kubernetes-model-certificates-6.7.2.jar:/usr/local/spark/jars/datanucleus-rdbms-4.1.19.jar:/usr/local/spark/jars/kubernetes-model-admissionregistration-6.7.2.jar:/usr/local/spark/jars/spark-kvstore_2.12-3.5.3.jar:/usr/local/spark/jars/libthrift-0.12.0.jar:/usr/local/spark/jars/xz-1.9.jar:/usr/local/spark/jars/arrow-vector-12.0.1.jar:/usr/local/spark/jars/scala-compiler-2.12.18.jar:/usr/local/spark/jars/hive-beeline-2.3.9.jar:/usr/local/spark/jars/guava-14.0.1.jar:/usr/local/spark/jars/jakarta.validation-api-2.0.2.jar:/usr/local/spark/jars/parquet-encoding-1.13.1.jar:/usr/local/spark/jars/spark-tags_2.12-3.5.3.jar:/usr/local/spark/jars/avro-ipc-1.11.2.jar:/usr/local/spark/jars/kubernetes-model-extensions-6.7.2.jar:/usr/local/spark/jars/jackson-dataformat-yaml-2.15.2.jar:/usr/local/spark/jars/curator-client-2.13.0.jar:/usr/local/spark/jars/jackson-module-scala_2.12-2.15.2.jar:/usr/local/spark/jars/metrics-core-4.2.19.jar:/usr/local/spark/jars/jackson-mapper-asl-1.9.13.jar:/usr/local/spark/jars/hive-shims-common-2.3.9.jar:/usr/local/spark/jars/kubernetes-model-batch-6.7.2.jar:/usr/local/spark/jars/spark-repl_2.12-3.5.3.jar:/usr/local/spark/jars/kubernetes-model-networking-6.7.2.jar:/usr/local/spark/jars/istack-commons-runtime-3.0.8.jar:/usr/local/spark/jars/commons-crypto-1.1.0.jar:/usr/local/spark/jars/bonecp-0.8.0.RELEASE.jar:/usr/local/spark/jars/hive-cli-2.3.9.jar:/usr/local/spark/jars/libfb303-0.9.3.jar:/usr/local/spark/jars/zookeeper-3.6.3.jar:/usr/local/spark/jars/chill_2.12-0.10.0.jar:/usr/local/spark/jars/arpack-3.0.3.jar:/usr/local/spark/jars/hive-exec-2.3.9-core.jar:/usr/local/spark/jars/hive-llap-common-2.3.9.jar:/usr/local/spark/jars/commons-io-2.16.1.jar:/usr/local/spark/jars/jackson-datatype-jsr310-2.15.2.jar:/usr/local/spark/jars/threeten-extra-1.7.1.jar:/usr/local/spark/jars/jersey-container-servlet-2.40.jar:/usr/local/spark/jars/httpclient-4.5.14.jar:/usr/local/spark/jars/lapack-3.0.3.jar:/usr/local/spark/jars/avro-mapred-1.11.2.jar:/usr/local/spark/jars/datasketches-java-3.3.0.jar:/usr/local/spark/jars/gson-2.2.4.jar:/usr/local/spark/jars/zstd-jni-1.5.5-4.jar:/usr/local/spark/jars/jersey-container-servlet-core-2.40.jar:/usr/local/spark/jars/javassist-3.29.2-GA.jar:/usr/local/spark/jars/hive-shims-0.23-2.3.9.jar:/usr/local/spark/jars/json-1.8.jar:/usr/local/spark/jars/shims-0.9.45.jar:/usr/local/spark/jars/scala-collection-compat_2.12-2.7.0.jar:/usr/local/spark/jars/orc-shims-1.9.4.jar:/usr/local/spark/jars/breeze-macros_2.12-2.1.0.jar:/usr/local/spark/jars/commons-cli-1.5.0.jar:/usr/local/spark/jars/kubernetes-model-gatewayapi-6.7.2.jar:/usr/local/spark/jars/commons-math3-3.6.1.jar:/usr/local/spark/jars/jta-1.1.jar:/usr/local/spark/jars/objenesis-3.3.jar:/usr/local/spark/jars/jersey-hk2-2.40.jar:/usr/local/spark/jars/spark-mesos_2.12-3.5.3.jar:/usr/local/spark/jars/jul-to-slf4j-2.0.7.jar:/usr/local/spark/jars/arrow-format-12.0.1.jar:/usr/local/spark/jars/aircompressor-0.27.jar:/usr/local/spark/jars/spark-network-common_2.12-3.5.3.jar:/usr/local/spark/jars/kubernetes-client-api-6.7.2.jar:/usr/local/spark/jars/hk2-locator-2.6.1.jar:/usr/local/spark/jars/json4s-ast_2.12-3.7.0-M11.jar:/usr/local/spark/jars/hive-shims-2.3.9.jar:/usr/local/spark/jars/netty-codec-socks-4.1.96.Final.jar:/usr/local/spark/jars/spark-graphx_2.12-3.5.3.jar:/usr/local/spark/jars/netty-resolver-4.1.96.Final.jar:/usr/local/spark/jars/datasketches-memory-2.1.0.jar:/usr/local/spark/jars/rocksdbjni-8.3.2.jar:/usr/local/spark/jars/py4j-0.10.9.7.jar:/usr/local/spark/jars/zookeeper-jute-3.6.3.jar:/usr/local/spark/jars/netty-codec-http2-4.1.96.Final.jar:/usr/local/spark/jars/scala-xml_2.12-2.1.0.jar:/usr/local/spark/jars/spark-hive-thriftserver_2.12-3.5.3.jar:/usr/local/spark/jars/commons-dbcp-1.4.jar:/usr/local/spark/jars/jakarta.inject-2.6.1.jar:/usr/local/spark/jars/algebra_2.12-2.0.1.jar:/usr/local/spark/jars/JTransforms-3.1.jar:/usr/local/spark/jars/metrics-json-4.2.19.jar:/usr/local/spark/jars/hk2-api-2.6.1.jar:/usr/local/spark/jars/zjsonpatch-0.3.0.jar:/usr/local/spark/jars/mesos-1.4.3-shaded-protobuf.jar:/usr/local/spark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-x86_64.jar:/usr/local/spark/jars/kubernetes-model-flowcontrol-6.7.2.jar:/usr/local/spark/jars/minlog-1.3.0.jar:/usr/local/spark/jars/opencsv-2.3.jar:/usr/local/spark/jars/arpack_combined_all-0.1.jar:/usr/local/spark/jars/kubernetes-model-rbac-6.7.2.jar:/usr/local/spark/jars/log4j-1.2-api-2.20.0.jar:/usr/local/spark/jars/breeze_2.12-2.1.0.jar:/usr/local/spark/jars/commons-collections4-4.4.jar:/usr/local/spark/jars/slf4j-api-2.0.7.jar:/usr/local/spark/jars/netty-handler-proxy-4.1.96.Final.jar:/usr/local/spark/jars/spark-network-shuffle_2.12-3.5.3.jar:/usr/local/spark/jars/jersey-client-2.40.jar:/usr/local/spark/jars/json4s-jackson_2.12-3.7.0-M11.jar:/usr/local/spark/jars/commons-collections-3.2.2.jar:/usr/local/spark/jars/spark-yarn_2.12-3.5.3.jar:/usr/local/spark/jars/activation-1.1.1.jar:/usr/local/spark/jars/kubernetes-model-common-6.7.2.jar:/usr/local/spark/jars/kubernetes-model-discovery-6.7.2.jar:/usr/local/spark/jars/spark-hive_2.12-3.5.3.jar:/usr/local/spark/jars/parquet-common-1.13.1.jar:/usr/local/spark/jars/log4j-slf4j2-impl-2.20.0.jar:/usr/local/spark/jars/netty-common-4.1.96.Final.jar:/usr/local/spark/jars/spire-macros_2.12-0.17.0.jar:/usr/local/spark/jars/ivy-2.5.1.jar:/usr/local/spark/jars/commons-text-1.10.0.jar:/usr/local/spark/jars/antlr-runtime-3.5.2.jar:/usr/local/spark/jars/netty-codec-http-4.1.96.Final.jar:/usr/local/spark/jars/hive-jdbc-2.3.9.jar:/usr/local/spark/jars/hadoop-shaded-guava-1.1.1.jar:/usr/local/spark/jars/spark-sql-api_2.12-3.5.3.jar:/usr/local/spark/jars/arrow-memory-netty-12.0.1.jar:/usr/local/spark/jars/spark-core_2.12-3.5.3.jar:/usr/local/spark/jars/netty-all-4.1.96.Final.jar:/usr/local/spark/jars/jackson-core-asl-1.9.13.jar:/usr/local/spark/jars/parquet-jackson-1.13.1.jar:/usr/local/spark/jars/kryo-shaded-4.0.2.jar:/usr/local/spark/jars/netty-transport-classes-kqueue-4.1.96.Final.jar:/usr/local/spark/jars/javax.jdo-3.2.0-m3.jar:/usr/local/spark/jars/super-csv-2.2.0.jar:/usr/local/spark/jars/snakeyaml-engine-2.6.jar:/usr/local/spark/jars/netty-buffer-4.1.96.Final.jar:/usr/local/spark/jars/spark-unsafe_2.12-3.5.3.jar:/usr/local/spark/jars/jline-2.14.6.jar:/usr/local/spark/jars/spire-platform_2.12-0.17.0.jar:/usr/local/spark/jars/kubernetes-model-core-6.7.2.jar:/usr/local/spark/jars/hk2-utils-2.6.1.jar:/usr/local/spark/jars/spark-streaming_2.12-3.5.3.jar:/usr/local/spark/jars/kubernetes-model-node-6.7.2.jar:/usr/local/spark/jars/jpam-1.1.jar:/usr/local/spark/jars/kubernetes-model-policy-6.7.2.jar:/usr/local/spark/jars/jackson-core-2.15.2.jar:/usr/local/spark/jars/json4s-scalap_2.12-3.7.0-M11.jar:/usr/local/spark/jars/kubernetes-model-apps-6.7.2.jar:/usr/local/spark/jars/jakarta.ws.rs-api-2.1.6.jar:/usr/local/spark/jars/spark-mllib_2.12-3.5.3.jar:/usr/local/spark/jars/jersey-common-2.40.jar:/usr/local/spark/jars/netty-transport-native-kqueue-4.1.96.Final-osx-aarch_64.jar:/usr/local/spark/jars/hive-metastore-2.3.9.jar:/usr/local/spark/jars/jodd-core-3.5.2.jar:/usr/local/spark/jars/parquet-hadoop-1.13.1.jar:/usr/local/spark/jars/spark-launcher_2.12-3.5.3.jar:/usr/local/spark/jars/javolution-5.5.1.jar:/usr/local/spark/jars/jakarta.xml.bind-api-2.3.2.jar:/usr/local/spark/jars/stax-api-1.0.1.jar:/usr/local/spark/jars/hadoop-client-runtime-3.3.4.jar:/usr/local/spark/jars/leveldbjni-all-1.8.jar:/usr/local/spark/jars/commons-compiler-3.1.9.jar:/usr/local/spark/jars/metrics-graphite-4.2.19.jar:/usr/local/spark/jars/spark-common-utils_2.12-3.5.3.jar:/usr/local/spark/jars/scala-reflect-2.12.18.jar:/usr/local/spark/jars/lz4-java-1.8.0.jar:/usr/local/spark/jars/kubernetes-httpclient-okhttp-6.7.2.jar:/usr/local/spark/jars/netty-handler-4.1.96.Final.jar:/usr/local/spark/jars/janino-3.1.9.jar:/usr/local/spark/jars/netty-transport-classes-epoll-4.1.96.Final.jar:/usr/local/spark/jars/jakarta.servlet-api-4.0.3.jar:/usr/local/spark/jars/scala-parser-combinators_2.12-2.3.0.jar:/usr/local/spark/jars/parquet-column-1.13.1.jar:/usr/local/spark/jars/kubernetes-model-events-6.7.2.jar:/usr/local/spark/jars/spire-util_2.12-0.17.0.jar:/usr/local/spark/jars/HikariCP-2.5.1.jar:/usr/local/spark/jars/log4j-core-2.20.0.jar:/usr/local/spark/jars/jackson-databind-2.15.2.jar:/usr/local/spark/jars/commons-lang-2.6.jar:/usr/local/spark/jars/cats-kernel_2.12-2.1.1.jar:/usr/local/spark/jars/transaction-api-1.1.jar:/usr/local/spark/jars/arrow-memory-core-12.0.1.jar:/usr/local/spark/jars/hive-service-rpc-3.1.3.jar:/usr/local/spark/jars/annotations-17.0.0.jar:/usr/local/spark/jars/kubernetes-model-apiextensions-6.7.2.jar:/usr/local/spark/jars/blas-3.0.3.jar:/usr/local/spark/jars/kubernetes-client-6.7.2.jar:/usr/local/spark/jars/joda-time-2.12.5.jar:/usr/local/spark/jars/jcl-over-slf4j-2.0.7.jar:/usr/local/spark/jars/spark-mllib-local_2.12-3.5.3.jar:/usr/local/spark/jars/jakarta.annotation-api-1.3.5.jar:/usr/local/spark/jars/JLargeArrays-1.5.jar:/usr/local/spark/jars/commons-logging-1.1.3.jar:/usr/local/spark/jars/okhttp-3.12.12.jar:/usr/local/spark/jars/kubernetes-model-scheduling-6.7.2.jar:/usr/local/spark/jars/hive-shims-scheduler-2.3.9.jar:/usr/local/spark/jars/netty-transport-native-epoll-4.1.96.Final-linux-x86_64.jar:/usr/local/spark/jars/tink-1.9.0.jar:/usr/local/spark/jars/hive-common-2.3.9.jar:/usr/local/spark/jars/kubernetes-model-metrics-6.7.2.jar:/usr/local/spark/jars/flatbuffers-java-1.12.0.jar:/usr/local/spark/jars/log4j-api-2.20.0.jar:/usr/local/spark/jars/okio-1.17.6.jar:/usr/local/spark/jars/orc-mapreduce-1.9.4-shaded-protobuf.jar:/usr/local/spark/jars/compress-lzf-1.1.2.jar:/usr/local/spark/jars/parquet-format-structures-1.13.1.jar:/usr/local/spark/jars/derby-10.14.2.0.jar:/usr/local/spark/jars/hive-storage-api-2.8.1.jar:/usr/local/spark/jars/hadoop-client-api-3.3.4.jar:/usr/local/spark/jars/pickle-1.3.jar:/usr/local/spark/jars/metrics-jvm-4.2.19.jar:/usr/local/spark/jars/spark-sql_2.12-3.5.3.jar:/usr/local/spark/jars/kafka-clients-3.3.1.jar:/usr/local/spark/jars/spark-sql-kafka-0-10_2.12-3.5.3.jar:/usr/local/spark/jars/spark-token-provider-kafka-0-10_2.12-3.5.3.jar:/usr/local/spark/jars/commons-pool2-2.11.1.jar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/conda/lib/python3.11/socket.py\", line 718, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 48\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Output to console with truncate=False to show full messages\u001b[39;00m\n\u001b[1;32m     41\u001b[0m query \u001b[38;5;241m=\u001b[39m df \\\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;241m.\u001b[39mwriteStream \\\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mappend\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \\\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \\\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m---> 48\u001b[0m \u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/pyspark/sql/streaming/query.py:221\u001b[0m, in \u001b[0;36mStreamingQuery.awaitTermination\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsq\u001b[38;5;241m.\u001b[39mawaitTermination(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\"\"\"\n",
    "in order to check this script you need to enter in the docker container and execute the file manually.\n",
    "check the kafka UI to see the topic dequeueing the messages and check the spark ui as well \n",
    "to see the processing.\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, from_json\n",
    "from pyspark.sql.types import StringType, StructType, StructField\n",
    "\n",
    "# spark session with kafka enabled\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"KafkaSparkIntegration\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "    .config(\"spark.sql.streaming.checkpointLocation\", \"/tmp/checkpoint\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set log level to reduce noise -> stdout in console is shown\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "\n",
    "# debugging the classpath\n",
    "print(\"Java classpath:\")\n",
    "print(spark.sparkContext._jvm.System.getProperty(\"java.class.path\"))\n",
    "\n",
    "# read stream from test-topic\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:9092\") \\\n",
    "    .option(\"subscribe\", \"test-topic\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "# processing the data.\n",
    "df = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "# show processing in console\n",
    "query = df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", False) \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
