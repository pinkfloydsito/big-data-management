{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1574fb1a-305a-43bf-9057-966b71977b43",
   "metadata": {},
   "source": [
    "## dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3565b05b-59bd-4645-b24c-f31f2ac7ed86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, window, unix_timestamp, max\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F\n",
    "import math\n",
    "import time\n",
    "\n",
    "from delta import *\n",
    "from delta.tables import *\n",
    "from pyspark.sql.functions import col, to_json, struct, lit, current_timestamp, expr, when, from_json, window\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    DoubleType,\n",
    "    TimestampType,\n",
    "    IntegerType,\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a391d04e-1693-44c7-be9e-2f86411bca4e",
   "metadata": {},
   "source": [
    "## schema definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff6fc29-daef-43a2-9c28-47a9310965eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a consistent warehouse directory path - use absolute path\n",
    "WAREHOUSE_DIR = \"/home/jovyan/spark-warehouse\"\n",
    "\n",
    "# Create the schema definition for NYC taxi data\n",
    "def create_raw_taxi_schema():\n",
    "    \"\"\"\n",
    "    Create the complete schema for NYC taxi data based on the DEBS Grand Challenge 2015 specification\n",
    "    \n",
    "    This schema includes all fields from the original dataset:\n",
    "    - Basic identifiers (medallion, hack_license)\n",
    "    - Time data (pickup_datetime, dropoff_datetime, trip_time_in_secs)\n",
    "    - Trip information (trip_distance)\n",
    "    - Location coordinates (pickup/dropoff longitude/latitude)\n",
    "    - Payment information (payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount)\n",
    "    \"\"\"\n",
    "    return StructType([\n",
    "        # Taxi and driver identifiers\n",
    "        StructField(\"medallion\", StringType(), True),         # Taxi vehicle identifier (md5sum)\n",
    "        StructField(\"hack_license\", StringType(), True),      # Taxi license identifier (md5sum)\n",
    "        \n",
    "        # Trip time information\n",
    "        StructField(\"pickup_datetime\", TimestampType(), True),   # Time of passenger pickup\n",
    "        StructField(\"dropoff_datetime\", TimestampType(), True),  # Time of passenger dropoff\n",
    "        StructField(\"trip_time_in_secs\", IntegerType(), True),   # Duration of the trip in seconds\n",
    "        \n",
    "        # Trip distance\n",
    "        StructField(\"trip_distance\", DoubleType(), True),     # Trip distance in miles\n",
    "        \n",
    "        # Pickup coordinates\n",
    "        StructField(\"pickup_longitude\", DoubleType(), True),  # Longitude coordinate of pickup\n",
    "        StructField(\"pickup_latitude\", DoubleType(), True),   # Latitude coordinate of pickup\n",
    "        \n",
    "        # Dropoff coordinates\n",
    "        StructField(\"dropoff_longitude\", DoubleType(), True), # Longitude coordinate of dropoff\n",
    "        StructField(\"dropoff_latitude\", DoubleType(), True),  # Latitude coordinate of dropoff\n",
    "        \n",
    "        # Payment information\n",
    "        StructField(\"payment_type\", StringType(), True),      # Payment method (credit card or cash)\n",
    "        StructField(\"fare_amount\", DoubleType(), True),       # Fare amount in dollars\n",
    "        StructField(\"surcharge\", DoubleType(), True),         # Surcharge in dollars\n",
    "        StructField(\"mta_tax\", DoubleType(), True),           # Tax in dollars\n",
    "        StructField(\"tip_amount\", DoubleType(), True),        # Tip in dollars\n",
    "        StructField(\"tolls_amount\", DoubleType(), True),      # Bridge and tunnel tolls in dollars\n",
    "        \n",
    "        # Additional fields that may be present\n",
    "        StructField(\"total_amount\", DoubleType(), True)       # Total amount paid (calculated field)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2484dc30-5360-48ba-878c-b1556af6d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Spark Session\n",
    "def create_spark_session(app_name=\"FrequentRoutes\"):\n",
    "    \"\"\"\n",
    "    start spark session with kafka and delta support / memory config setup too\n",
    "    \"\"\"\n",
    "    builder = SparkSession.builder.appName(app_name) \\\n",
    "        .config(\"spark.sql.session.timeZone\", \"UTC\") \\\n",
    "        .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "        .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "        .config(\"spark.sql.warehouse.dir\", WAREHOUSE_DIR) \\\n",
    "        .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "        .config(\"spark.driver.memory\", \"5g\") \\\n",
    "        .config(\"spark.executor.memory\", \"4g\") \\\n",
    "        .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "        .config(\"spark.memory.offHeap.size\", \"2g\") \\\n",
    "        .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "        .config(\"spark.default.parallelism\", \"100\") \\\n",
    "        .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "        .config(\"spark.sql.debug.maxToStringFields\", 100) \\\n",
    "        .enableHiveSupport()\n",
    "    \n",
    "    # delta config\n",
    "    spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "    \n",
    "    # do not flood logs\n",
    "    spark.sparkContext.setLogLevel(\"WARN\")\n",
    "    \n",
    "    # Print configs for debugging\n",
    "    print(f\"Warehouse directory: {spark.conf.get('spark.sql.warehouse.dir')}\")\n",
    "    print(f\"Catalog implementation: {spark.conf.get('spark.sql.catalogImplementation')}\")\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77fba9f-16d1-4969-a0d9-190901baa1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse directory: file:/home/jovyan/spark-warehouse\n",
      "Catalog implementation: hive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 46698)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Spark session\n",
    "spark = create_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d46127e-4dfb-40a8-a54a-fa52a608f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_taxi_schema = create_raw_taxi_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b422b75-8daf-44d8-9380-35bb7a910b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define paths\n",
    "CLEAN_TABLE_NAME = \"clean_taxi_data\"\n",
    "FREQ_TABLE_NAME = \"freq_taxi_data\"\n",
    "\n",
    "CLEAN_OUTPUT_PATH = os.path.join(WAREHOUSE_DIR, CLEAN_TABLE_NAME)\n",
    "FREQ_OUTPUT_PATH = os.path.join(WAREHOUSE_DIR, FREQ_TABLE_NAME)\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(WAREHOUSE_DIR, \"streaming/checkpoints\")\n",
    "CLEAN_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"clean_taxi_data\")\n",
    "\n",
    "FREQ_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"frequent_routes\")\n",
    "FREQ_ROUTES_CHECKPOINT_PATH = os.path.join(CHECKPOINT_DIR, \"frequent_routes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c74aca4d-c10f-46c1-acf3-881d2967e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a table once streaming data is available\n",
    "def create_table_if_exists(output_path, table_name):\n",
    "    \"\"\"\n",
    "    Check if data exists in the given path and create a table pointing to it\n",
    "    \"\"\"\n",
    "    data_exists = False\n",
    "    for _i in range(30):  # Longer timeout to 30 seconds\n",
    "        try:\n",
    "            time.sleep(120)\n",
    "            if os.path.exists(output_path):\n",
    "                files = os.listdir(output_path)\n",
    "                for _f in files:\n",
    "                    if \".parquet\" in _f:\n",
    "                        if os.path.exists(f\"{output_path}/_delta_log\") and len(os.listdir(f\"{output_path}/_delta_log\")) > 0:\n",
    "                            print(f\"Data exists in {output_path}\")\n",
    "                            data_exists = True\n",
    "                            break\n",
    "            if data_exists:\n",
    "                # Create external table with explicit location\n",
    "                spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "                spark.sql(f\"CREATE TABLE {table_name} USING DELTA LOCATION '{output_path}'\")\n",
    "                print(f\"Created table {table_name} using data at {output_path}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting for data: {e}\")\n",
    "            pass\n",
    "    \n",
    "    if not data_exists:\n",
    "        print(f\"WARNING: No data found in {output_path} after waiting. Table may not be created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b70cbb94-dac8-40c8-b732-a6604d3a660b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "CELL_SIZE = 500  # size of grid cell in meters\n",
    "ORIGIN_LAT = 41.474937  # Latitude of cell 1.1\n",
    "ORIGIN_LON = -74.913585  # Longitude of cell 1.1\n",
    "MAX_CELL = 300  # grid expands 150km with 500m cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dacf8051-448b-4c37-aae4-4c8b7decedc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_cell_id(lat, lon)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper functions to convert lat/lon to cell coordinates\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Function to compute grid cell ID\n",
    "def get_cell_id(lat, lon):\n",
    "    base_lat, base_lon = 41.474937, -74.913585  # NYC reference point\n",
    "    cell_size = 0.0045  # Approx. 500m in degrees\n",
    "\n",
    "    cell_x = int((lon - base_lon) / cell_size) + 1\n",
    "    cell_y = int((base_lat - lat) / cell_size) + 1\n",
    "    return f\"{cell_x}.{cell_y}\"\n",
    "\n",
    "# Register UDFs\n",
    "spark.udf.register(\"get_cell_id\", get_cell_id, StringType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8a3062-0dc3-4c96-b615-6ddba1e3f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.readStream.format(\"delta\").load(CLEAN_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9157fccf-ff45-49b4-a908-8582058e0126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: top 10 in 30 minutes window. data is already sorted.\n",
    "def query1_part1(clean_taxi_data):\n",
    "    # Convert coordinates to grid cells\n",
    "    routes_df = df.withColumn(\n",
    "        \"start_cell\", \n",
    "        F.expr(\"get_cell_id(pickup_latitude, pickup_longitude)\")\n",
    "    ).withColumn(\n",
    "        \"end_cell\", \n",
    "        F.expr(\"get_cell_id(dropoff_latitude, dropoff_longitude)\")\n",
    "    )    \n",
    "    \n",
    "    # 30 minutes sliding window\n",
    "    windowed_routes = routes_df.withWatermark(\"dropoff_datetime\", \"30 minutes\") \\\n",
    "        .groupBy(\n",
    "            F.window(\"dropoff_datetime\", \"30 minutes\"),\n",
    "            \"start_cell\", \n",
    "            \"end_cell\"\n",
    "        ) \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"Number_of_Rides\")\n",
    "    \n",
    "    # top 10 routes from stream\n",
    "    top_routes = windowed_routes \\\n",
    "        .select(\"window\", \"start_cell\", \"end_cell\", \"Number_of_Rides\") \\\n",
    "        .orderBy(col(\"Number_of_Rides\").desc()) \\\n",
    "        # .limit(10)\n",
    "    return top_routes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3aec328-e53d-4e4d-a14d-398af123e74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|dropoff_datetime   |\n",
      "+-------------------+\n",
      "|2014-01-01 00:36:00|\n",
      "|2014-01-01 00:27:13|\n",
      "|2014-01-01 00:24:00|\n",
      "|2014-01-01 00:23:00|\n",
      "|2014-01-01 00:18:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_df = spark.read.format(\"delta\").load(CLEAN_OUTPUT_PATH)\n",
    "batch_df.select(\"dropoff_datetime\").orderBy(\"dropoff_datetime\", ascending=False).limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cb3cff5-8fa1-4dcc-a71e-33ce59055780",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 653000), medallion='3567E8B49FEBFCBB587F1864D723D5C8', hack_license='430B8022563CDE1D51D44786DFD8D6CB', pickup_datetime=datetime.datetime(2013, 10, 19, 20, 37, 8), dropoff_datetime=datetime.datetime(2013, 10, 19, 20, 57, 20), trip_time_in_secs=1211, trip_distance=2.0, pickup_longitude=-73.982338, pickup_latitude=40.731693, dropoff_longitude=-73.988419, dropoff_latitude=40.750069, payment_type='CRD', fare_amount=14.0, surcharge=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, total_amount=15.0, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 653000), medallion='B620FF1CD0B80A120894F7A1D376582D', hack_license='76AC51FFFF22C9A6416560A8F70E2CB0', pickup_datetime=datetime.datetime(2013, 4, 23, 15, 36), dropoff_datetime=datetime.datetime(2013, 4, 23, 15, 48), trip_time_in_secs=696, trip_distance=1.5, pickup_longitude=-73.992599, pickup_latitude=40.733925, dropoff_longitude=-73.989075, dropoff_latitude=40.72242, payment_type='CRD', fare_amount=9.0, surcharge=0.0, mta_tax=0.5, tip_amount=1.0, tolls_amount=0.0, total_amount=10.5, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 652000), medallion='59E8BDEBA9E2E83AA2D3664A3E1CB779', hack_license='DA2141D19E936BD6D940428B7727FF43', pickup_datetime=datetime.datetime(2013, 1, 27, 12, 17), dropoff_datetime=datetime.datetime(2013, 1, 27, 12, 25), trip_time_in_secs=480, trip_distance=1.28, pickup_longitude=-73.987152, pickup_latitude=40.759838, dropoff_longitude=-73.991661, dropoff_latitude=40.749931, payment_type='CSH', fare_amount=7.0, surcharge=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, total_amount=7.5, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 652000), medallion='BE0D66D2F076E9E0D89FCCA98E32015F', hack_license='F7802B88F3429CFF1B3646227C31C2BF', pickup_datetime=datetime.datetime(2013, 12, 6, 23, 4), dropoff_datetime=datetime.datetime(2013, 12, 6, 23, 7), trip_time_in_secs=180, trip_distance=0.41, pickup_longitude=-73.958595, pickup_latitude=40.721184, dropoff_longitude=-73.959862, dropoff_latitude=40.718296, payment_type='CSH', fare_amount=4.0, surcharge=0.5, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, total_amount=5.0, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 652000), medallion='7CF14F4AF8B8EDB15DE23A404FD37E9E', hack_license='61838464E95BE90E6C8CE7E4EE204636', pickup_datetime=datetime.datetime(2013, 5, 25, 11, 39, 20), dropoff_datetime=datetime.datetime(2013, 5, 25, 11, 51, 8), trip_time_in_secs=708, trip_distance=1.5, pickup_longitude=-73.957298, pickup_latitude=40.770275, dropoff_longitude=-73.971626, dropoff_latitude=40.754799, payment_type='CRD', fare_amount=9.5, surcharge=0.0, mta_tax=0.5, tip_amount=1.25, tolls_amount=0.0, total_amount=11.25, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 664000), medallion='C2DEADDEF7389342F257E61A6D3DB01A', hack_license='071B87EBA88764FAD7C5694362B93168', pickup_datetime=datetime.datetime(2013, 4, 23, 15, 41), dropoff_datetime=datetime.datetime(2013, 4, 23, 15, 48), trip_time_in_secs=420, trip_distance=1.59, pickup_longitude=-73.949631, pickup_latitude=40.772667, dropoff_longitude=-73.947777, dropoff_latitude=40.787228, payment_type='CSH', fare_amount=7.0, surcharge=0.0, mta_tax=0.5, tip_amount=0.0, tolls_amount=0.0, total_amount=7.5, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 652000), medallion='5562E98BA4BD4057E5626F1C64AF72B3', hack_license='B850A506A372259D59D4D8423E0FD0DD', pickup_datetime=datetime.datetime(2013, 3, 29, 15, 5), dropoff_datetime=datetime.datetime(2013, 3, 29, 15, 24), trip_time_in_secs=1140, trip_distance=9.14, pickup_longitude=-73.870743, pickup_latitude=40.773415, dropoff_longitude=-73.958214, dropoff_latitude=40.761086, payment_type='CRD', fare_amount=28.0, surcharge=0.0, mta_tax=0.5, tip_amount=7.5, tolls_amount=0.0, total_amount=36.0, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 664000), medallion='841441CA91D0E47151759F884BBD72AD', hack_license='E6513E9AD03A4AF10C0354BA71BA68A4', pickup_datetime=datetime.datetime(2013, 1, 27, 12, 12), dropoff_datetime=datetime.datetime(2013, 1, 27, 12, 25), trip_time_in_secs=780, trip_distance=2.85, pickup_longitude=-73.978119, pickup_latitude=40.749233, dropoff_longitude=-74.006943, dropoff_latitude=40.727062, payment_type='CRD', fare_amount=11.5, surcharge=0.0, mta_tax=0.5, tip_amount=1.0, tolls_amount=0.0, total_amount=13.0, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 664000), medallion='D6DF6AD4DF90402E74365B775FCEEFB2', hack_license='32FC997A27DCF783459318019FAE8B21', pickup_datetime=datetime.datetime(2013, 4, 23, 15, 31), dropoff_datetime=datetime.datetime(2013, 4, 23, 15, 48), trip_time_in_secs=1020, trip_distance=1.34, pickup_longitude=-73.97184, pickup_latitude=40.753788, dropoff_longitude=-73.990189, dropoff_latitude=40.751331, payment_type='CRD', fare_amount=11.0, surcharge=0.0, mta_tax=0.5, tip_amount=2.2, tolls_amount=0.0, total_amount=13.7, start_cell=None, end_cell=None, Number_of_Rides=None),\n",
       " Row(kafka_key=None, kafka_timestamp=datetime.datetime(2025, 3, 28, 17, 45, 9, 664000), medallion='62AB75789A51B5D51B473A63FAAB935A', hack_license='85076CACF5F842FFEAD43096C46F3735', pickup_datetime=datetime.datetime(2013, 3, 29, 15, 14), dropoff_datetime=datetime.datetime(2013, 3, 29, 15, 24), trip_time_in_secs=600, trip_distance=2.48, pickup_longitude=-73.970467, pickup_latitude=40.764996, dropoff_longitude=-73.975487, dropoff_latitude=40.789558, payment_type='CRD', fare_amount=10.0, surcharge=0.0, mta_tax=0.5, tip_amount=2.5, tolls_amount=0.0, total_amount=13.0, start_cell=None, end_cell=None, Number_of_Rides=None)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39360838-ee08-4376-96c7-3fb9f63a61b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|dropoff_datetime   |\n",
      "+-------------------+\n",
      "|2013-01-01 00:03:00|\n",
      "|2013-01-01 00:05:49|\n",
      "|2013-01-01 00:06:00|\n",
      "|2013-01-01 00:06:46|\n",
      "|2013-01-01 00:06:54|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_df.select(\"dropoff_datetime\").orderBy(\"dropoff_datetime\").limit(5).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5d39651-27e6-4272-a124-96e21b927a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kafka_key',\n",
       " 'kafka_timestamp',\n",
       " 'medallion',\n",
       " 'hack_license',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'trip_time_in_secs',\n",
       " 'trip_distance',\n",
       " 'pickup_longitude',\n",
       " 'pickup_latitude',\n",
       " 'dropoff_longitude',\n",
       " 'dropoff_latitude',\n",
       " 'payment_type',\n",
       " 'fare_amount',\n",
       " 'surcharge',\n",
       " 'mta_tax',\n",
       " 'tip_amount',\n",
       " 'tolls_amount',\n",
       " 'total_amount',\n",
       " 'start_cell',\n",
       " 'end_cell',\n",
       " 'Number_of_Rides']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "213b7460-56f5-4b3d-95f0-a158fac88f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6871525"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcfa3cca-2e23-4594-a991-aac5edb8e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_longitude_count = batch_df.filter(F.col(\"pickup_longitude\").isNull()).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c48ee67e-9199-4618-8339-bba24e538e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_longitude_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "264c0a1e-d909-49fb-a2b0-24825e19865d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_df.filter(F.col(\"pickup_latitude\").isNull()).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e927c8aa-ece9-4e14-9b90-501217901d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_longitude_count = batch_df.filter(F.isnan(\"pickup_longitude\")).count()\n",
    "nan_latitude_count = batch_df.filter(F.isnan(\"pickup_latitude\")).count()\n",
    "nan_longitude_count, nan_latitude_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7eee3eb-61e1-4d04-b645-0de5bf752813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data spans from 2013-01-01 00:03:00 to 2014-01-01 00:36:00\n"
     ]
    }
   ],
   "source": [
    "time_range = batch_df.agg(\n",
    "    F.min(\"dropoff_datetime\").alias(\"earliest_dropoff\"),\n",
    "    F.max(\"dropoff_datetime\").alias(\"latest_dropoff\")\n",
    ").collect()[0]\n",
    "    \n",
    "print(f\"\\nData spans from {time_range['earliest_dropoff']} to {time_range['latest_dropoff']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7697b371-b3f7-4dc9-9b77-4764d8b97177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_df = df.withColumn(\n",
    "    \"pickup_datetime\", F.to_timestamp(\"pickup_datetime\")\n",
    ").withColumn(\n",
    "    \"dropoff_datetime\", F.to_timestamp(\"dropoff_datetime\")\n",
    ")\n",
    "    \n",
    "# Run Query 1, Part 1\n",
    "part1_results = query1_part1(clean_df)\n",
    "\n",
    "query1_part1_stream = (part1_results.writeStream\n",
    "    .outputMode(\"complete\")\n",
    "    .format(\"delta\")\n",
    "    .queryName(\"frequent_routes\")\n",
    "    .trigger(processingTime=\"3 second\")\n",
    "    .option(\"checkpointLocation\", FREQ_CHECKPOINT_PATH)\n",
    "    .start(FREQ_OUTPUT_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a82b8b8-c155-4aa9-98e9-53b514b1a147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Waiting for next trigger',\n",
       " 'isDataAvailable': False,\n",
       " 'isTriggerActive': False}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query1_part1_stream.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36615c-f4f0-450c-bc81-3530d0ed9c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_if_exists(FREQ_OUTPUT_PATH, FREQ_TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbacde64-7b03-4115-8bd4-0bf33975cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_batch_df = spark.read.format(\"delta\").load(FREQ_OUTPUT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ad5aeaf-caca-4c38-b793-9e1f9f7d11d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6653605"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_batch_df.count()\n",
    "\n",
    "#pandas_df = freq_batch_df.toPandas()\n",
    "\n",
    "# Print the Pandas DataFrame\n",
    "#print(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab21a188-a41f-4de2-8e92-d8d1c20392b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_window = freq_batch_df \\\n",
    "    .select(\"window\") \\\n",
    "    .orderBy(col(\"window.end\").desc()) \\\n",
    "    .limit(1) \\\n",
    "    .collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b79126b9-c7a5-4a05-961b-cc5d25aa9f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rides_window = freq_batch_df.orderBy(col(\"window.end\").desc(), col(\"Number_Of_Rides\").desc()).limit(1).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d6eb292-32a9-4d43-8858-c97054e455d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_start, window_end = max_rides_window[\"start\"], max_rides_window[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "865f8e4d-e081-420c-982f-27ccdc69da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2014, 1, 1, 0, 30), datetime.datetime(2014, 1, 1, 1, 0))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_start, window_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b1dc4-c7e4-477a-af98-9da02976f592",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9598d435-41da-46d1-bb79-c19866fbb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_time = freq_batch_df.agg(F.max(\"window.end\")).collect()[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "697f2f14-870e-4ac5-b524-5c07655d809c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2014, 1, 1, 1, 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92af450b-c627-45cb-92ba-8a008eb25e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_min_ago = latest_time - pd.Timedelta(minutes=30)\n",
    "\n",
    "top_routes = freq_batch_df \\\n",
    "    .filter(col(\"window.end\") >= thirty_min_ago) \\\n",
    "    .select(\n",
    "        col(\"window.start\").alias(\"window_start\"),\n",
    "        col(\"window.end\").alias(\"window_end\"),\n",
    "        \"start_cell\", \n",
    "        \"end_cell\", \n",
    "        \"Number_of_Rides\"\n",
    "    ) \\\n",
    "    .orderBy(col(\"Number_of_Rides\").desc()) \\\n",
    "    .limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "435258f1-81e6-48c8-91bd-bf1e40e9e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "thirty_min_ago = window_end - pd.Timedelta(minutes=30)\n",
    "\n",
    "top_routes_max_window = freq_batch_df \\\n",
    "    .filter(col(\"window.end\") >= thirty_min_ago) \\\n",
    "    .select(\n",
    "        col(\"window.start\").alias(\"window_start\"),\n",
    "        col(\"window.end\").alias(\"window_end\"),\n",
    "        \"start_cell\", \n",
    "        \"end_cell\", \n",
    "        \"Number_of_Rides\"\n",
    "    ) \\\n",
    "    .orderBy(col(\"Number_of_Rides\").desc()) \\\n",
    "    .limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8a1aa6c-0324-41de-946e-dbf9fc386c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Windows by Ride Count:\n",
      "+-------------------+-------------------+-----------+\n",
      "|       window_start|         window_end|total_rides|\n",
      "+-------------------+-------------------+-----------+\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|       1033|\n",
      "+-------------------+-------------------+-----------+\n",
      "\n",
      "\n",
      "Top 10 Routes per Top Window (null for missing ranks):\n",
      "+-------------------+-------------------+----+----------+----------+---------------+\n",
      "|       window_start|         window_end|rank|start_cell|  end_cell|Number_of_Rides|\n",
      "+-------------------+-------------------+----+----------+----------+---------------+\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   1|16648.9217|16648.9217|              6|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   2|   206.165|   209.162|              3|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   2|   207.162|   208.166|              3|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   2|   206.165|   208.163|              3|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   3|      NULL|      NULL|           NULL|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   4|      NULL|      NULL|           NULL|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   212.169|   215.167|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   206.168|   202.171|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   202.164|   204.159|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   202.164|   206.163|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   205.167|   205.164|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   206.169|   203.163|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   204.168|   204.164|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   207.166|   202.171|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   211.160|   215.156|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   206.168|   207.165|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   206.160|   213.157|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   209.158|   205.161|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   214.156|   221.159|              2|\n",
      "|2013-11-03 01:30:00|2013-11-03 02:00:00|   5|   203.166|   203.164|              2|\n",
      "+-------------------+-------------------+----+----------+----------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = freq_batch_df.withColumn(\"window_start\", F.col(\"window.start\")) \\\n",
    "       .withColumn(\"window_end\", F.col(\"window.end\"))\n",
    "\n",
    "# Find top windows based on ride count\n",
    "window_counts = df.groupBy(\"window_start\", \"window_end\") \\\n",
    "    .agg(F.sum(\"Number_of_Rides\").alias(\"total_rides\")) \\\n",
    "    .orderBy(F.desc(\"total_rides\"))\n",
    "\n",
    "# Get the top window (or windows if there's a tie)\n",
    "top_window = window_counts.first()\n",
    "top_window_rides = top_window[\"total_rides\"]\n",
    "top_windows = window_counts.filter(F.col(\"total_rides\") == top_window_rides)\n",
    "\n",
    "# Get the top 10 routes for each top window\n",
    "windowSpec = Window.partitionBy(\"window_start\", \"window_end\").orderBy(F.desc(\"Number_of_Rides\"))\n",
    "routes_with_rank = df.join(\n",
    "    top_windows, \n",
    "    [\"window_start\", \"window_end\"]\n",
    ").withColumn(\"rank\", F.rank().over(windowSpec))\n",
    "\n",
    "# Get top 10 routes per window\n",
    "top_routes = routes_with_rank.filter(F.col(\"rank\") <= 10)\n",
    "\n",
    "# If there are fewer than 10 routes for a window, we need to pad with nulls\n",
    "# First, create a sequence from 1 to 10\n",
    "rank_df = spark.range(1, 11).withColumnRenamed(\"id\", \"rank\")\n",
    "\n",
    "# Create a cross join between top windows and ranks\n",
    "window_rank_template = top_windows.crossJoin(rank_df)\n",
    "\n",
    "# Do a left outer join to fill missing ranks with nulls\n",
    "final_result = window_rank_template.join(\n",
    "    top_routes,\n",
    "    [\"window_start\", \"window_end\", \"rank\"],\n",
    "    \"left_outer\"\n",
    ").orderBy(\"window_start\", \"window_end\", \"rank\")\n",
    "\n",
    "# Select only the columns we need for the final output\n",
    "final_result = final_result.select(\n",
    "    \"window_start\",\n",
    "    \"window_end\",\n",
    "    \"rank\",\n",
    "    \"start_cell\",\n",
    "    \"end_cell\",\n",
    "    \"Number_of_Rides\"\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Top Windows by Ride Count:\")\n",
    "top_windows.show()\n",
    "\n",
    "print(\"\\nTop 10 Routes per Top Window (null for missing ranks):\")\n",
    "final_result.show(20)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bef56c8-471e-4b4c-b41f-9d5eb5e21305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='211.160', end_cell='210.158', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='252.185', end_cell='210.177', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='205.161', end_cell='216.144', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='202.168', end_cell='209.153', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='211.159', end_cell='212.155', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.157', end_cell='214.156', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.158', end_cell='205.162', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.178', end_cell='213.179', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.156', end_cell='214.153', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='216.155', end_cell='233.137', Number_of_Rides=1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_routes_max_window.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "569272f8-0fbc-4dac-b1a3-144bffda3659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='211.160', end_cell='210.158', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='252.185', end_cell='210.177', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='205.161', end_cell='216.144', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='202.168', end_cell='209.153', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='211.159', end_cell='212.155', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.157', end_cell='214.156', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.158', end_cell='205.162', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.178', end_cell='213.179', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='207.156', end_cell='214.153', Number_of_Rides=1),\n",
       " Row(window_start=datetime.datetime(2014, 1, 1, 0, 0), window_end=datetime.datetime(2014, 1, 1, 0, 30), start_cell='216.155', end_cell='233.137', Number_of_Rides=1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_routes.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f06d2ffd-f5a5-4a79-9efb-6569d9cc5c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>start_cell</th>\n",
       "      <th>end_cell</th>\n",
       "      <th>Number_of_Rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>211.160</td>\n",
       "      <td>210.158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>252.185</td>\n",
       "      <td>210.177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>205.161</td>\n",
       "      <td>216.144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>202.168</td>\n",
       "      <td>209.153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>211.159</td>\n",
       "      <td>212.155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.157</td>\n",
       "      <td>214.156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.158</td>\n",
       "      <td>205.162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.178</td>\n",
       "      <td>213.179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.156</td>\n",
       "      <td>214.153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>216.155</td>\n",
       "      <td>233.137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  window_start          window_end start_cell end_cell  Number_of_Rides\n",
       "0   2014-01-01 2014-01-01 00:30:00    211.160  210.158                1\n",
       "1   2014-01-01 2014-01-01 00:30:00    252.185  210.177                1\n",
       "2   2014-01-01 2014-01-01 00:30:00    205.161  216.144                1\n",
       "3   2014-01-01 2014-01-01 00:30:00    202.168  209.153                1\n",
       "4   2014-01-01 2014-01-01 00:30:00    211.159  212.155                1\n",
       "5   2014-01-01 2014-01-01 00:30:00    207.157  214.156                1\n",
       "6   2014-01-01 2014-01-01 00:30:00    207.158  205.162                1\n",
       "7   2014-01-01 2014-01-01 00:30:00    207.178  213.179                1\n",
       "8   2014-01-01 2014-01-01 00:30:00    207.156  214.153                1\n",
       "9   2014-01-01 2014-01-01 00:30:00    216.155  233.137                1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df = top_routes.toPandas()\n",
    "\n",
    "# Print the Pandas DataFrame\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f35d4523-ca6a-4965-aff1-91ab1f0623b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_max_window_df = top_routes_max_window.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "168911f6-1a41-47c9-af77-879a3e64c5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>window_start</th>\n",
       "      <th>window_end</th>\n",
       "      <th>start_cell</th>\n",
       "      <th>end_cell</th>\n",
       "      <th>Number_of_Rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>211.160</td>\n",
       "      <td>210.158</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>252.185</td>\n",
       "      <td>210.177</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>205.161</td>\n",
       "      <td>216.144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>202.168</td>\n",
       "      <td>209.153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>211.159</td>\n",
       "      <td>212.155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.157</td>\n",
       "      <td>214.156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.158</td>\n",
       "      <td>205.162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.178</td>\n",
       "      <td>213.179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>207.156</td>\n",
       "      <td>214.153</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>2014-01-01 00:30:00</td>\n",
       "      <td>216.155</td>\n",
       "      <td>233.137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  window_start          window_end start_cell end_cell  Number_of_Rides\n",
       "0   2014-01-01 2014-01-01 00:30:00    211.160  210.158                1\n",
       "1   2014-01-01 2014-01-01 00:30:00    252.185  210.177                1\n",
       "2   2014-01-01 2014-01-01 00:30:00    205.161  216.144                1\n",
       "3   2014-01-01 2014-01-01 00:30:00    202.168  209.153                1\n",
       "4   2014-01-01 2014-01-01 00:30:00    211.159  212.155                1\n",
       "5   2014-01-01 2014-01-01 00:30:00    207.157  214.156                1\n",
       "6   2014-01-01 2014-01-01 00:30:00    207.158  205.162                1\n",
       "7   2014-01-01 2014-01-01 00:30:00    207.178  213.179                1\n",
       "8   2014-01-01 2014-01-01 00:30:00    207.156  214.153                1\n",
       "9   2014-01-01 2014-01-01 00:30:00    216.155  233.137                1"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_max_window_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbeeedf2-23eb-4918-aedf-33d4d71036e4",
   "metadata": {},
   "source": [
    "```bash\n",
    "big_data_project_pyspark  | Batch: 0\n",
    "big_data_project_pyspark  | -------------------------------------------\n",
    "big_data_project_pyspark  | +----------+--------+---------------+\n",
    "big_data_project_pyspark  | |start_cell|end_cell|Number_of_Rides|\n",
    "big_data_project_pyspark  | +----------+--------+---------------+\n",
    "big_data_project_pyspark  | |   156.160| 157.159|              7|\n",
    "big_data_project_pyspark  | |   156.160| 157.159|              7|\n",
    "big_data_project_pyspark  | |   156.160| 157.159|              7|\n",
    "big_data_project_pyspark  | |   157.159| 154.160|              7|\n",
    "big_data_project_pyspark  | |   157.159| 154.160|              7|\n",
    "big_data_project_pyspark  | |   158.160| 159.159|              7|\n",
    "big_data_project_pyspark  | |   156.160| 157.159|              6|\n",
    "big_data_project_pyspark  | |   156.160| 158.160|              6|\n",
    "big_data_project_pyspark  | |   158.160| 159.159|              6|\n",
    "big_data_project_pyspark  | |   156.160| 157.159|              6|\n",
    "big_data_project_pyspark  | +----------+--------+---------------+\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dc27c4-a834-4c6c-98d3-51e7424a43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results\n",
    "# XXX: check this :'c top_routes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b9191-8ac6-4ff6-9803-40815cd76aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the batch processing\n",
    "part2_results = query1_part2_batch(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246894ac-35f8-4296-b9e1-2ee7e4712824",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_results.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
