{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "284fd29c-b41b-4b1e-969a-de9b4797fb6f",
   "metadata": {},
   "source": [
    "# Checkpoint 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fdf5d1-2735-4e9e-a906-6a815a511dc3",
   "metadata": {},
   "source": [
    "## Fetch the data and persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654aa07f-95de-44bc-bc13-031bd93676b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-09 15:22:58--  https://archive.org/download/nycTaxiTripData2013/trip_data.7z\n",
      "Resolving archive.org (archive.org)... 207.241.224.2\n",
      "Connecting to archive.org (archive.org)|207.241.224.2|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ia902202.us.archive.org/28/items/nycTaxiTripData2013/trip_data.7z [following]\n",
      "--2025-03-09 15:22:58--  https://ia902202.us.archive.org/28/items/nycTaxiTripData2013/trip_data.7z\n",
      "Resolving ia902202.us.archive.org (ia902202.us.archive.org)... 207.241.228.62\n",
      "Connecting to ia902202.us.archive.org (ia902202.us.archive.org)|207.241.228.62|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4102781969 (3.8G) [application/x-7z-compressed]\n",
      "Saving to: ‘trip_data.7z’\n",
      "\n",
      "trip_data.7z        100%[===================>]   3.82G   417KB/s    in 91m 50s \n",
      "\n",
      "2025-03-09 16:54:49 (727 KB/s) - ‘trip_data.7z’ saved [4102781969/4102781969]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.org/download/nycTaxiTripData2013/trip_data.7z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f3b40-a089-4452-8966-0a4b0aa55742",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv trip_data.7z input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01f59d0-b89a-49a5-9358-de14c08ab868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely==2.0.7\n",
      "  Using cached shapely-2.0.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\n",
      "Collecting delta-spark==3.3.0\n",
      "  Using cached delta_spark-3.3.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: py7zr==0.22.0 in /opt/conda/lib/python3.11/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/conda/lib/python3.11/site-packages (from shapely==2.0.7) (1.26.4)\n",
      "Requirement already satisfied: pyspark<3.6.0,>=3.5.3 in /usr/local/spark/python (from delta-spark==3.3.0) (3.5.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from delta-spark==3.3.0) (8.5.0)\n",
      "Requirement already satisfied: texttable in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (1.7.0)\n",
      "Requirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (3.21.0)\n",
      "Requirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (0.16.2)\n",
      "Requirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (1.1.1)\n",
      "Requirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (1.0.3)\n",
      "Requirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (0.2.3)\n",
      "Requirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (1.0.1)\n",
      "Requirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (1.1.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from py7zr==0.22.0) (6.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata>=1.0.0->delta-spark==3.3.0) (3.20.2)\n",
      "Collecting py4j==0.10.9.7 (from pyspark<3.6.0,>=3.5.3->delta-spark==3.3.0)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Using cached shapely-2.0.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (2.4 MB)\n",
      "Using cached delta_spark-3.3.0-py3-none-any.whl (21 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, shapely, delta-spark\n",
      "Successfully installed delta-spark-3.3.0 py4j-0.10.9.7 shapely-2.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install shapely==2.0.7 delta-spark==3.3.0 py7zr==0.22.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0002cc5b-fbd4-465a-9a84-bd3abb8fb33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted input/trip_data.7z to input/prod\n"
     ]
    }
   ],
   "source": [
    "import py7zr\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def extract_7z(archive_path, output_dir):\n",
    "    with py7zr.SevenZipFile(archive_path, mode='r') as z:\n",
    "        z.extractall(path=output_dir)\n",
    "    print(f\"Extracted {archive_path} to {output_dir}\")\n",
    "\n",
    "archive_path = \"input/trip_data.7z\"\n",
    "output_dir = \"input/prod\"\n",
    "    \n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "        \n",
    "extract_7z(archive_path, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90076c3-73af-4e72-b21e-474416a94088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT! Remove the empty space in each cell of the header, schema parsing was erroring.\n",
    "# If erroring run it from the shell.\n",
    "!for file in input/prod/trip_data_*.csv; do sed -i '1s/, /,/g' \"$file\"; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad67cf9-24d4-44ee-8b53-d8e2fd1f294e",
   "metadata": {},
   "source": [
    "## Spark session with its configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf524691-b6db-4786-bc0a-510d059a7e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, unix_timestamp, lag, when, count, avg, lead, sum as spark_sum\n",
    "from pyspark.sql.window import Window\n",
    "import json\n",
    "from shapely.geometry import Point, Polygon, shape\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    IntegerType,\n",
    "    StringType,\n",
    "    DoubleType\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "885ee465-15a2-4173-8a6c-2faff7fe5789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/09 19:26:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"NYC Taxi Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\") \\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.3\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"100\") \\\n",
    "    .config(\"spark.default.parallelism\", \"20\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.adaptive.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")\n",
    "\n",
    "spark.sparkContext.setCheckpointDir(\"checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce10091-e6af-44c8-8e02-859770449211",
   "metadata": {},
   "source": [
    "## Load taxi rides dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcdfd81-2c6c-463b-a452-a03af7873222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for the data\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"medallion\", StringType()),\n",
    "        StructField(\"hack_license\", StringType()),\n",
    "        StructField(\"vendor_id\", StringType()),\n",
    "        StructField(\"rate_code\", StringType()),\n",
    "        StructField(\"store_and_fwd_flag\", StringType()),\n",
    "        StructField(\"pickup_datetime\", StringType()),\n",
    "        StructField(\n",
    "            \"dropoff_datetime\", StringType()\n",
    "        ),\n",
    "        StructField(\"passenger_count\", IntegerType()),\n",
    "        StructField(\"trip_time_in_secs\", StringType()),\n",
    "        StructField(\"trip_distance\", StringType()),\n",
    "        StructField(\"pickup_longitude\", DoubleType()),\n",
    "        StructField(\"pickup_latitude\", DoubleType()),\n",
    "        StructField(\"dropoff_longitude\", DoubleType()),\n",
    "        StructField(\"dropoff_latitude\", DoubleType()),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c199ed5-a0f9-41a9-b490-46c9a35baab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "# if parquet data is loaded, skip cell\n",
    "prod_path = \"input/trip_data_*.csv\"\n",
    "sample_path = \"input/sample.csv\"\n",
    "\n",
    "taxi_df = (\n",
    "    spark.read\n",
    "    .option(\"header\", True)\n",
    "    .schema(schema)\n",
    "    .csv(prod_path)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d739d67-ea9c-4268-aec4-4ceb8a98cf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(medallion='89D227B655E5C82AECF13C3F540D4CF4', hack_license='BA96DE419E711691B9445D6A6307C170', vendor_id='CMT', rate_code='1', store_and_fwd_flag='N', pickup_datetime='2013-01-01 15:11:48', dropoff_datetime='2013-01-01 15:18:10', passenger_count=4, trip_time_in_secs='382', trip_distance='1.00', pickup_longitude=-73.978165, pickup_latitude=40.757977, dropoff_longitude=-73.989838, dropoff_latitude=40.751171)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ede8444-b5b8-41e0-89dd-0c4f068c14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['medallion',\n",
    " 'hack_license',\n",
    " 'vendor_id',\n",
    " 'rate_code',\n",
    " 'store_and_fwd_flag',\n",
    " 'pickup_datetime',\n",
    " 'dropoff_datetime',\n",
    " 'passenger_count',\n",
    " 'trip_time_in_secs',\n",
    " 'trip_distance',\n",
    " 'pickup_longitude',\n",
    " 'pickup_latitude',\n",
    " 'dropoff_longitude',\n",
    " 'dropoff_latitude']\n",
    "columns_to_drop = [\"hack_license\", \"vendor_id\", \n",
    "                   \"rate_code\", \"store_and_fwd_flag\",\n",
    "                   \"passenger_count\", \"trip_time_in_secs\",\n",
    "                   \"trip_distance\"]\n",
    "df_dropped = taxi_df.drop(*columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1900e90-3538-4909-b69b-886552b50d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# skip cell if have parquet data\n",
    "df_dropped.write.parquet(\"input/prod/taxi_data.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
